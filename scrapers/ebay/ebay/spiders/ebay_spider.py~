import scrapy, time, re
from ebay.functions import ebay_item_parser
from ebay.urls import urls
from ebay.com_functions import csv_opener


class MySpider1(scrapy.Spider):
    name = 'ebay1'
    start_urls = ['http://www.ebay.in']
    allowed_domains = ['http://www.ebay.in']

    page1 = urls[0]['first_url']
    page2 = urls[0]['second_url']
    pgs = urls[0]['pages']
    category = urls[0]['cat_name']
    itms = 50

    fh = csv_opener('ebay')
    client, coll = mongo_db()

    def parse(self, response):
        yield scrapy.Request(self.page1, callback=self.parse_pages, dont_filter=True, meta={'category': self.category})
        for x in range(2, self.pgs):
            url = re.sub(r'skc=50&', 'skc=%s&', re.sub(r'pgn=2&', 'pgn=%s&', self.page2) % x) % self.itms
            #yield scrapy.Request(
            #    url, 
            #    callback=self.parse_pages, 
            #    dont_filter=True, 
            #    meta={'category': self.category}
            #)
            pg += 1
            itms += 50
            print url, '############################################################'

    def parse_pages(self, response):
        urls = response.xpath('.//ul[@id="ListViewInner"]/li/h3/a/@href').extract()
        for url in urls:
            yield scrapy.Request(
                url, 
                callback=self.parse_page, 
                dont_filter=True, 
                meta={'category': response.meta['category']}
            )

    def parse_page(self, response):
        ebay_item_parser(response, self.fh, response.meta['category'])          



